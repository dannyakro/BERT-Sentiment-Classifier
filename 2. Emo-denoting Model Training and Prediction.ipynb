{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This scripts runs additional pre-processing on the output\n",
    "in the first notebook and then runs Random Forest Classifier,\n",
    "Decision Tree Classifier and Logistic Regression to determine\n",
    "the optimal model for detecting whether a word is an emotion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "main_df = pd.read_csv('res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prediction</th>\n",
       "      <th>cleaned_index</th>\n",
       "      <th>Label</th>\n",
       "      <th>self_auth</th>\n",
       "      <th>self_class</th>\n",
       "      <th>self_deg</th>\n",
       "      <th>self_betcent</th>\n",
       "      <th>pred_betcent</th>\n",
       "      <th>pred_auth</th>\n",
       "      <th>pred_deg</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>string</th>\n",
       "      <th>from_textid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consistently_2</td>\n",
       "      <td>['also', 'being', 'actually', 'currently', 'st...</td>\n",
       "      <td>consistently</td>\n",
       "      <td>consistently</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, -1, 155965.9877]</td>\n",
       "      <td>[0.000391, 0.000651, 0.000391, -1, 0.000269]</td>\n",
       "      <td>[33, 125, 7, -1, 136]</td>\n",
       "      <td>[9, 3, 21, -1, 16]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rated_3</td>\n",
       "      <td>['performing', 'doing', 'functioning', 'workin...</td>\n",
       "      <td>rated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-1, 174890.4158, -1, 481.203593, 47866.10398]</td>\n",
       "      <td>[-1, 0.001086, -1, 0.001485, 0.000102]</td>\n",
       "      <td>[-1, 169, -1, 19, 9]</td>\n",
       "      <td>[-1, 25, -1, 8, 9]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poorly_5</td>\n",
       "      <td>['highly', 'high', 'low', 'well', 'poorly']</td>\n",
       "      <td>poorly</td>\n",
       "      <td>poorly</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>194.873669</td>\n",
       "      <td>[1816.335264, 0.0, 39966.12492, 0.0, 194.873669]</td>\n",
       "      <td>[0.015114, 0.00691, 0.005939, 0.0034, 0.001552]</td>\n",
       "      <td>[176, 198, 173, 135, 10]</td>\n",
       "      <td>[25, 23, 11, 5, 11]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seen_10</td>\n",
       "      <td>['written', 'done', 'read', 'said']</td>\n",
       "      <td>seen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-1, 0.0, 35.951423, -1]</td>\n",
       "      <td>[-1, 0.002634, 1.1e-05, -1]</td>\n",
       "      <td>[-1, 18, 8, -1]</td>\n",
       "      <td>[-1, 17, 0, -1]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contradicting_17</td>\n",
       "      <td>['but', 'and']</td>\n",
       "      <td>contradicting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6263.708295, 10269.73499]</td>\n",
       "      <td>[8.6e-05, 0.000116]</td>\n",
       "      <td>[26, 10]</td>\n",
       "      <td>[18, 8]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index                                         prediction  \\\n",
       "0    consistently_2  ['also', 'being', 'actually', 'currently', 'st...   \n",
       "1           rated_3  ['performing', 'doing', 'functioning', 'workin...   \n",
       "2          poorly_5        ['highly', 'high', 'low', 'well', 'poorly']   \n",
       "3           seen_10                ['written', 'done', 'read', 'said']   \n",
       "4  contradicting_17                                     ['but', 'and']   \n",
       "\n",
       "   cleaned_index         Label  self_auth  self_class  self_deg  self_betcent  \\\n",
       "0   consistently  consistently   0.000209        25.0      10.0      0.000000   \n",
       "1          rated           NaN        NaN         NaN       NaN           NaN   \n",
       "2         poorly        poorly   0.001552        11.0      10.0    194.873669   \n",
       "3           seen           NaN        NaN         NaN       NaN           NaN   \n",
       "4  contradicting           NaN        NaN         NaN       NaN           NaN   \n",
       "\n",
       "                                       pred_betcent  \\\n",
       "0                  [0.0, 0.0, 0.0, -1, 155965.9877]   \n",
       "1    [-1, 174890.4158, -1, 481.203593, 47866.10398]   \n",
       "2  [1816.335264, 0.0, 39966.12492, 0.0, 194.873669]   \n",
       "3                          [-1, 0.0, 35.951423, -1]   \n",
       "4                        [6263.708295, 10269.73499]   \n",
       "\n",
       "                                         pred_auth                  pred_deg  \\\n",
       "0     [0.000391, 0.000651, 0.000391, -1, 0.000269]     [33, 125, 7, -1, 136]   \n",
       "1           [-1, 0.001086, -1, 0.001485, 0.000102]      [-1, 169, -1, 19, 9]   \n",
       "2  [0.015114, 0.00691, 0.005939, 0.0034, 0.001552]  [176, 198, 173, 135, 10]   \n",
       "3                      [-1, 0.002634, 1.1e-05, -1]           [-1, 18, 8, -1]   \n",
       "4                              [8.6e-05, 0.000116]                  [26, 10]   \n",
       "\n",
       "            pred_class                                             string  \\\n",
       "0   [9, 3, 21, -1, 16]  Saxobank is consistently rated very poorly fro...   \n",
       "1   [-1, 25, -1, 8, 9]  Saxobank is consistently rated very poorly fro...   \n",
       "2  [25, 23, 11, 5, 11]  Saxobank is consistently rated very poorly fro...   \n",
       "3      [-1, 17, 0, -1]  Saxobank is consistently rated very poorly fro...   \n",
       "4              [18, 8]  Saxobank is consistently rated very poorly fro...   \n",
       "\n",
       "   from_textid  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renames the index column and snippet column\n",
    "main_df = main_df.rename(columns = {\"Unnamed: 0\":\"index\",\"string\":\"snippet\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads the exported Gephi file and assigns\n",
    "boolean values according to whether each label\n",
    "is an emotion or not\n",
    "\"\"\"\n",
    "emotions = pd.read_csv(\"../source_data/gephi_output_cleaned.csv\")[['Label','KEEP? (Y/N)']].rename(columns = {\"KEEP? (Y/N)\":\"emo?\"})\n",
    "emotions = emotions.dropna()\n",
    "emotions = emotions[emotions['emo?'].str.contains(\"Y|N\")]\n",
    "emotions['emo?'] = emotions['emo?'].apply(lambda x: 1 if x == \"Y\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines the pre-processed notebook with emotion labels\n",
    "main_df = pd.merge(main_df, emotions, left_on = 'cleaned_index', right_on = 'Label', how = 'left').dropna(subset = ['Label_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks for records where predicted betweenness centrality only has 1 element or if the first element is equals to -1 as this infers it is masked\n",
    "main_df['kind_of_useless'] = main_df.pred_betcent.apply(lambda x: True if len(list(set(ast.literal_eval(x)))) == 1 and list(set(ast.literal_eval(x)))[0] == -1 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean mask to extract the remaining records\n",
    "main_df = main_df[main_df.kind_of_useless == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4\n",
       "1.0    3\n",
       "Name: emo?, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts of emotion vs non-emotion words\n",
    "main_df['emo?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get words that do not denote emotions, that contain useful information\n",
    "i.e. : \n",
    "* pred_betcent list length is > 0 \n",
    "* the pred elements contain useful information \n",
    "* is not emotion denoting words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Id the TextData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prediction</th>\n",
       "      <th>cleaned_index</th>\n",
       "      <th>Label_x</th>\n",
       "      <th>self_auth</th>\n",
       "      <th>self_class</th>\n",
       "      <th>self_deg</th>\n",
       "      <th>self_betcent</th>\n",
       "      <th>pred_betcent</th>\n",
       "      <th>pred_auth</th>\n",
       "      <th>pred_deg</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>snippet</th>\n",
       "      <th>from_textid</th>\n",
       "      <th>Label_y</th>\n",
       "      <th>emo?</th>\n",
       "      <th>kind_of_useless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consistently_2</td>\n",
       "      <td>['also', 'being', 'actually', 'currently', 'st...</td>\n",
       "      <td>consistently</td>\n",
       "      <td>consistently</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, -1, 155965.9877]</td>\n",
       "      <td>[0.000391, 0.000651, 0.000391, -1, 0.000269]</td>\n",
       "      <td>[33, 125, 7, -1, 136]</td>\n",
       "      <td>[9, 3, 21, -1, 16]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>consistently</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poorly_5</td>\n",
       "      <td>['highly', 'high', 'low', 'well', 'poorly']</td>\n",
       "      <td>poorly</td>\n",
       "      <td>poorly</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>194.873669</td>\n",
       "      <td>[1816.335264, 0.0, 39966.12492, 0.0, 194.873669]</td>\n",
       "      <td>[0.015114, 0.00691, 0.005939, 0.0034, 0.001552]</td>\n",
       "      <td>[176, 198, 173, 135, 10]</td>\n",
       "      <td>[25, 23, 11, 5, 11]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>poorly</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>point_19</td>\n",
       "      <td>['pointing', 'pointed', 'point', 'points', 'fi...</td>\n",
       "      <td>point</td>\n",
       "      <td>point</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>24.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1, -1, 0.0, -1, -1]</td>\n",
       "      <td>[-1, -1, 0.002054, -1, -1]</td>\n",
       "      <td>[-1, -1, 242, -1, -1]</td>\n",
       "      <td>[-1, -1, 24, -1, -1]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>point</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sense_28</td>\n",
       "      <td>['good', 'quality', 'general', 'new', 'strict']</td>\n",
       "      <td>sense</td>\n",
       "      <td>sense</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 10972.03876, 2012.54884, 287.247587]</td>\n",
       "      <td>[0.013005, 0.101255, 0.000135, 0.001431, 0.000...</td>\n",
       "      <td>[398, 229, 13, 59, 43]</td>\n",
       "      <td>[18, 17, 5, 10, 12]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>sense</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>entire_7</td>\n",
       "      <td>['new', 'old', 'entire', 'former', 'current']</td>\n",
       "      <td>entire</td>\n",
       "      <td>entire</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[2012.54884, 0.0, 0.0, 0.0, 3153.12649]</td>\n",
       "      <td>[0.001431, 0.000349, 0.002084, 0.000104, 0.001...</td>\n",
       "      <td>[59, 66, 84, 22, 61]</td>\n",
       "      <td>[10, 10, 5, 15, 8]</td>\n",
       "      <td>I wonder what would happen if the entire WSB a...</td>\n",
       "      <td>4</td>\n",
       "      <td>entire</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index                                         prediction  \\\n",
       "0   consistently_2  ['also', 'being', 'actually', 'currently', 'st...   \n",
       "2         poorly_5        ['highly', 'high', 'low', 'well', 'poorly']   \n",
       "5         point_19  ['pointing', 'pointed', 'point', 'points', 'fi...   \n",
       "7         sense_28    ['good', 'quality', 'general', 'new', 'strict']   \n",
       "24        entire_7      ['new', 'old', 'entire', 'former', 'current']   \n",
       "\n",
       "   cleaned_index       Label_x  self_auth  self_class  self_deg  self_betcent  \\\n",
       "0   consistently  consistently   0.000209        25.0      10.0      0.000000   \n",
       "2         poorly        poorly   0.001552        11.0      10.0    194.873669   \n",
       "5          point         point   0.002054        24.0     242.0      0.000000   \n",
       "7          sense         sense   0.000308         4.0     116.0      0.000000   \n",
       "24        entire        entire   0.002084         5.0      84.0      0.000000   \n",
       "\n",
       "                                        pred_betcent  \\\n",
       "0                   [0.0, 0.0, 0.0, -1, 155965.9877]   \n",
       "2   [1816.335264, 0.0, 39966.12492, 0.0, 194.873669]   \n",
       "5                              [-1, -1, 0.0, -1, -1]   \n",
       "7    [0.0, 0.0, 10972.03876, 2012.54884, 287.247587]   \n",
       "24           [2012.54884, 0.0, 0.0, 0.0, 3153.12649]   \n",
       "\n",
       "                                            pred_auth  \\\n",
       "0        [0.000391, 0.000651, 0.000391, -1, 0.000269]   \n",
       "2     [0.015114, 0.00691, 0.005939, 0.0034, 0.001552]   \n",
       "5                          [-1, -1, 0.002054, -1, -1]   \n",
       "7   [0.013005, 0.101255, 0.000135, 0.001431, 0.000...   \n",
       "24  [0.001431, 0.000349, 0.002084, 0.000104, 0.001...   \n",
       "\n",
       "                    pred_deg            pred_class  \\\n",
       "0      [33, 125, 7, -1, 136]    [9, 3, 21, -1, 16]   \n",
       "2   [176, 198, 173, 135, 10]   [25, 23, 11, 5, 11]   \n",
       "5      [-1, -1, 242, -1, -1]  [-1, -1, 24, -1, -1]   \n",
       "7     [398, 229, 13, 59, 43]   [18, 17, 5, 10, 12]   \n",
       "24      [59, 66, 84, 22, 61]    [10, 10, 5, 15, 8]   \n",
       "\n",
       "                                              snippet  from_textid  \\\n",
       "0   Saxobank is consistently rated very poorly fro...            0   \n",
       "2   Saxobank is consistently rated very poorly fro...            0   \n",
       "5   Saxobank is consistently rated very poorly fro...            0   \n",
       "7   Saxobank is consistently rated very poorly fro...            0   \n",
       "24  I wonder what would happen if the entire WSB a...            4   \n",
       "\n",
       "         Label_y  emo?  kind_of_useless  \n",
       "0   consistently   0.0            False  \n",
       "2         poorly   1.0            False  \n",
       "5          point   0.0            False  \n",
       "7          sense   0.0            False  \n",
       "24        entire   0.0            False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_ = main_df.copy()\n",
    "all_data_ = all_data_.drop(columns = ['kind_of_useless'])\n",
    "all_data_ = all_data_.drop(columns = ['Label_y']).rename(columns = {\"Label_x\":\"Label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prediction</th>\n",
       "      <th>cleaned_index</th>\n",
       "      <th>Label</th>\n",
       "      <th>self_auth</th>\n",
       "      <th>self_class</th>\n",
       "      <th>self_deg</th>\n",
       "      <th>self_betcent</th>\n",
       "      <th>pred_betcent</th>\n",
       "      <th>pred_auth</th>\n",
       "      <th>pred_deg</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>snippet</th>\n",
       "      <th>from_textid</th>\n",
       "      <th>emo?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consistently_2</td>\n",
       "      <td>['also', 'being', 'actually', 'currently', 'st...</td>\n",
       "      <td>consistently</td>\n",
       "      <td>consistently</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, -1, 155965.9877]</td>\n",
       "      <td>[0.000391, 0.000651, 0.000391, -1, 0.000269]</td>\n",
       "      <td>[33, 125, 7, -1, 136]</td>\n",
       "      <td>[9, 3, 21, -1, 16]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poorly_5</td>\n",
       "      <td>['highly', 'high', 'low', 'well', 'poorly']</td>\n",
       "      <td>poorly</td>\n",
       "      <td>poorly</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>194.873669</td>\n",
       "      <td>[1816.335264, 0.0, 39966.12492, 0.0, 194.873669]</td>\n",
       "      <td>[0.015114, 0.00691, 0.005939, 0.0034, 0.001552]</td>\n",
       "      <td>[176, 198, 173, 135, 10]</td>\n",
       "      <td>[25, 23, 11, 5, 11]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>point_19</td>\n",
       "      <td>['pointing', 'pointed', 'point', 'points', 'fi...</td>\n",
       "      <td>point</td>\n",
       "      <td>point</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>24.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1, -1, 0.0, -1, -1]</td>\n",
       "      <td>[-1, -1, 0.002054, -1, -1]</td>\n",
       "      <td>[-1, -1, 242, -1, -1]</td>\n",
       "      <td>[-1, -1, 24, -1, -1]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sense_28</td>\n",
       "      <td>['good', 'quality', 'general', 'new', 'strict']</td>\n",
       "      <td>sense</td>\n",
       "      <td>sense</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 10972.03876, 2012.54884, 287.247587]</td>\n",
       "      <td>[0.013005, 0.101255, 0.000135, 0.001431, 0.000...</td>\n",
       "      <td>[398, 229, 13, 59, 43]</td>\n",
       "      <td>[18, 17, 5, 10, 12]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>entire_7</td>\n",
       "      <td>['new', 'old', 'entire', 'former', 'current']</td>\n",
       "      <td>entire</td>\n",
       "      <td>entire</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[2012.54884, 0.0, 0.0, 0.0, 3153.12649]</td>\n",
       "      <td>[0.001431, 0.000349, 0.002084, 0.000104, 0.001...</td>\n",
       "      <td>[59, 66, 84, 22, 61]</td>\n",
       "      <td>[10, 10, 5, 15, 8]</td>\n",
       "      <td>I wonder what would happen if the entire WSB a...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index                                         prediction  \\\n",
       "0   consistently_2  ['also', 'being', 'actually', 'currently', 'st...   \n",
       "2         poorly_5        ['highly', 'high', 'low', 'well', 'poorly']   \n",
       "5         point_19  ['pointing', 'pointed', 'point', 'points', 'fi...   \n",
       "7         sense_28    ['good', 'quality', 'general', 'new', 'strict']   \n",
       "24        entire_7      ['new', 'old', 'entire', 'former', 'current']   \n",
       "\n",
       "   cleaned_index         Label  self_auth  self_class  self_deg  self_betcent  \\\n",
       "0   consistently  consistently   0.000209        25.0      10.0      0.000000   \n",
       "2         poorly        poorly   0.001552        11.0      10.0    194.873669   \n",
       "5          point         point   0.002054        24.0     242.0      0.000000   \n",
       "7          sense         sense   0.000308         4.0     116.0      0.000000   \n",
       "24        entire        entire   0.002084         5.0      84.0      0.000000   \n",
       "\n",
       "                                        pred_betcent  \\\n",
       "0                   [0.0, 0.0, 0.0, -1, 155965.9877]   \n",
       "2   [1816.335264, 0.0, 39966.12492, 0.0, 194.873669]   \n",
       "5                              [-1, -1, 0.0, -1, -1]   \n",
       "7    [0.0, 0.0, 10972.03876, 2012.54884, 287.247587]   \n",
       "24           [2012.54884, 0.0, 0.0, 0.0, 3153.12649]   \n",
       "\n",
       "                                            pred_auth  \\\n",
       "0        [0.000391, 0.000651, 0.000391, -1, 0.000269]   \n",
       "2     [0.015114, 0.00691, 0.005939, 0.0034, 0.001552]   \n",
       "5                          [-1, -1, 0.002054, -1, -1]   \n",
       "7   [0.013005, 0.101255, 0.000135, 0.001431, 0.000...   \n",
       "24  [0.001431, 0.000349, 0.002084, 0.000104, 0.001...   \n",
       "\n",
       "                    pred_deg            pred_class  \\\n",
       "0      [33, 125, 7, -1, 136]    [9, 3, 21, -1, 16]   \n",
       "2   [176, 198, 173, 135, 10]   [25, 23, 11, 5, 11]   \n",
       "5      [-1, -1, 242, -1, -1]  [-1, -1, 24, -1, -1]   \n",
       "7     [398, 229, 13, 59, 43]   [18, 17, 5, 10, 12]   \n",
       "24      [59, 66, 84, 22, 61]    [10, 10, 5, 15, 8]   \n",
       "\n",
       "                                              snippet  from_textid  emo?  \n",
       "0   Saxobank is consistently rated very poorly fro...            0   0.0  \n",
       "2   Saxobank is consistently rated very poorly fro...            0   1.0  \n",
       "5   Saxobank is consistently rated very poorly fro...            0   0.0  \n",
       "7   Saxobank is consistently rated very poorly fro...            0   0.0  \n",
       "24  I wonder what would happen if the entire WSB a...            4   0.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking the data with - 1 does not work with large datasets, drop these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "This jupyter notebook is used to train simple model to predict emo-denoting words from the BERT prediction output\n",
    "\n",
    "### Training Data Preparation\n",
    "* Part of the BERT prediction output shall be labelled with 1/0 for emotion-denoting under a 'Label' column\n",
    "* The labelled part of the data are used in the supervised training with 30% of them used as validation set\n",
    "* **bert_output_path** is a variable for you to pass the path of the bert model prediction output from the BERT model prediction notebook\n",
    "\n",
    "### Model Training\n",
    "* Three models (random forest, decision tree, logistic regression) are included in the code for your model selection , feature importance, accuracy and f1-score on the test set\n",
    "* Change **model_select** variable to the desired one\n",
    "\n",
    "### Model Prediction result\n",
    "* Ouput file name **emo_pred_file_name** can be modified in the first cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "\n",
    "### folder directory\n",
    "output_folder=\"New_RunTime_Output/\"\n",
    "model_save_folder = \"GME_Models/\"\n",
    "\n",
    "\n",
    "### read the BERT output csv file with \"emo?\" label \n",
    "emo_pred_file_name=\"pred_with_rfc\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model input data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_output = all_data_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = bert_output[['index','Label','self_auth','self_deg','self_betcent','pred_auth','pred_deg','pred_betcent','from_textid']]\n",
    "\"\"\"\n",
    "Make sure you have your emotions column as the y column\n",
    "\"\"\"\n",
    "### This is the prediction results\n",
    "bert_y = bert_output['emo?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winst\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "### get the training data for the emo-denoting word prediction , get those data with \"Label\"\n",
    "### Reformat the data such that the values are -1\n",
    "for col in ['self_auth','self_deg','self_betcent']:\n",
    "    input_text.loc[input_text['Label'].isna(),col] =- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate average auth score from the BERT predicted words\n",
    "by cumulatively summing the scores divided by the total count\n",
    "to get the average\n",
    "\"\"\"\n",
    "\n",
    "def cal_avg_pred_score(row):\n",
    "    count = 0\n",
    "    sum_ = 0\n",
    "    for item in row:\n",
    "        item = item.strip()\n",
    "        # -1 is used to mask missing values\n",
    "        if item.strip() != '-1' or item.strip() != \"\":\n",
    "            try:\n",
    "                sum_ += float(item)\n",
    "                count+= 1\n",
    "            except: \n",
    "                pass\n",
    "    if count==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum_/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>self_auth</th>\n",
       "      <th>self_deg</th>\n",
       "      <th>self_betcent</th>\n",
       "      <th>pred_auth</th>\n",
       "      <th>pred_deg</th>\n",
       "      <th>pred_betcent</th>\n",
       "      <th>from_textid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consistently_2</td>\n",
       "      <td>consistently</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.000391, 0.000651, 0.000391, -1, 0.000269]</td>\n",
       "      <td>[33, 125, 7, -1, 136]</td>\n",
       "      <td>[0.0, 0.0, 0.0, -1, 155965.9877]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poorly_5</td>\n",
       "      <td>poorly</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>10.0</td>\n",
       "      <td>194.873669</td>\n",
       "      <td>[0.015114, 0.00691, 0.005939, 0.0034, 0.001552]</td>\n",
       "      <td>[176, 198, 173, 135, 10]</td>\n",
       "      <td>[1816.335264, 0.0, 39966.12492, 0.0, 194.873669]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>point_19</td>\n",
       "      <td>point</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1, -1, 0.002054, -1, -1]</td>\n",
       "      <td>[-1, -1, 242, -1, -1]</td>\n",
       "      <td>[-1, -1, 0.0, -1, -1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sense_28</td>\n",
       "      <td>sense</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.013005, 0.101255, 0.000135, 0.001431, 0.000...</td>\n",
       "      <td>[398, 229, 13, 59, 43]</td>\n",
       "      <td>[0.0, 0.0, 10972.03876, 2012.54884, 287.247587]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>entire_7</td>\n",
       "      <td>entire</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.001431, 0.000349, 0.002084, 0.000104, 0.001...</td>\n",
       "      <td>[59, 66, 84, 22, 61]</td>\n",
       "      <td>[2012.54884, 0.0, 0.0, 0.0, 3153.12649]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mean_2</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.102042</td>\n",
       "      <td>423.0</td>\n",
       "      <td>97091.279300</td>\n",
       "      <td>[0.000248, 0.000348, -1, 0.01506]</td>\n",
       "      <td>[31, 144, -1, 155]</td>\n",
       "      <td>[104792.6541, 0.0, -1, 44742.32375]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>safe_28</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>14.0</td>\n",
       "      <td>70.224625</td>\n",
       "      <td>[0.000251, 0.000332, 0.000116, 0.002862, 4.7e-05]</td>\n",
       "      <td>[58, 48, 10, 199, 6]</td>\n",
       "      <td>[0.0, 11410.48432, 10269.73499, 0.0, 0.0]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index         Label  self_auth  self_deg  self_betcent  \\\n",
       "0   consistently_2  consistently   0.000209      10.0      0.000000   \n",
       "2         poorly_5        poorly   0.001552      10.0    194.873669   \n",
       "5         point_19         point   0.002054     242.0      0.000000   \n",
       "7         sense_28         sense   0.000308     116.0      0.000000   \n",
       "24        entire_7        entire   0.002084      84.0      0.000000   \n",
       "33          mean_2          mean   0.102042     423.0  97091.279300   \n",
       "44         safe_28          safe   0.000259      14.0     70.224625   \n",
       "\n",
       "                                            pred_auth  \\\n",
       "0        [0.000391, 0.000651, 0.000391, -1, 0.000269]   \n",
       "2     [0.015114, 0.00691, 0.005939, 0.0034, 0.001552]   \n",
       "5                          [-1, -1, 0.002054, -1, -1]   \n",
       "7   [0.013005, 0.101255, 0.000135, 0.001431, 0.000...   \n",
       "24  [0.001431, 0.000349, 0.002084, 0.000104, 0.001...   \n",
       "33                  [0.000248, 0.000348, -1, 0.01506]   \n",
       "44  [0.000251, 0.000332, 0.000116, 0.002862, 4.7e-05]   \n",
       "\n",
       "                    pred_deg  \\\n",
       "0      [33, 125, 7, -1, 136]   \n",
       "2   [176, 198, 173, 135, 10]   \n",
       "5      [-1, -1, 242, -1, -1]   \n",
       "7     [398, 229, 13, 59, 43]   \n",
       "24      [59, 66, 84, 22, 61]   \n",
       "33        [31, 144, -1, 155]   \n",
       "44      [58, 48, 10, 199, 6]   \n",
       "\n",
       "                                        pred_betcent  from_textid  \n",
       "0                   [0.0, 0.0, 0.0, -1, 155965.9877]            0  \n",
       "2   [1816.335264, 0.0, 39966.12492, 0.0, 194.873669]            0  \n",
       "5                              [-1, -1, 0.0, -1, -1]            0  \n",
       "7    [0.0, 0.0, 10972.03876, 2012.54884, 287.247587]            0  \n",
       "24           [2012.54884, 0.0, 0.0, 0.0, 3153.12649]            4  \n",
       "33               [104792.6541, 0.0, -1, 44742.32375]            7  \n",
       "44         [0.0, 11410.48432, 10269.73499, 0.0, 0.0]            9  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winst\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\winst\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "### convert string list to float list for further calculations\n",
    "for col in ['pred_auth','pred_deg','pred_betcent']:\n",
    "    input_text[col] = input_text[col].str.replace(\"'\",\"\",).str.replace(\"[\",\"\").str.replace(\"]\",\"\").str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winst\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "### Run avg calculation for the following columns\n",
    "for col in ['pred_auth','pred_deg','pred_betcent']:\n",
    "    input_text['avg_'+col]= input_text[col].map(lambda x: cal_avg_pred_score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Label</th>\n",
       "      <th>self_auth</th>\n",
       "      <th>self_deg</th>\n",
       "      <th>self_betcent</th>\n",
       "      <th>pred_auth</th>\n",
       "      <th>pred_deg</th>\n",
       "      <th>pred_betcent</th>\n",
       "      <th>from_textid</th>\n",
       "      <th>avg_pred_auth</th>\n",
       "      <th>avg_pred_deg</th>\n",
       "      <th>avg_pred_betcent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consistently_2</td>\n",
       "      <td>consistently</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.000391,  0.000651,  0.000391,  -1,  0.000269]</td>\n",
       "      <td>[33,  125,  7,  -1,  136]</td>\n",
       "      <td>[0.0,  0.0,  0.0,  -1,  155965.9877]</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.199660</td>\n",
       "      <td>60.0</td>\n",
       "      <td>31192.997540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poorly_5</td>\n",
       "      <td>poorly</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>10.0</td>\n",
       "      <td>194.873669</td>\n",
       "      <td>[0.015114,  0.00691,  0.005939,  0.0034,  0.00...</td>\n",
       "      <td>[176,  198,  173,  135,  10]</td>\n",
       "      <td>[1816.335264,  0.0,  39966.12492,  0.0,  194.8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>138.4</td>\n",
       "      <td>8395.466771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>point_19</td>\n",
       "      <td>point</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1,  -1,  0.002054,  -1,  -1]</td>\n",
       "      <td>[-1,  -1,  242,  -1,  -1]</td>\n",
       "      <td>[-1,  -1,  0.0,  -1,  -1]</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.799589</td>\n",
       "      <td>47.6</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sense_28</td>\n",
       "      <td>sense</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.013005,  0.101255,  0.000135,  0.001431,  0...</td>\n",
       "      <td>[398,  229,  13,  59,  43]</td>\n",
       "      <td>[0.0,  0.0,  10972.03876,  2012.54884,  287.24...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023204</td>\n",
       "      <td>148.4</td>\n",
       "      <td>2654.367037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>entire_7</td>\n",
       "      <td>entire</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.001431,  0.000349,  0.002084,  0.000104,  0...</td>\n",
       "      <td>[59,  66,  84,  22,  61]</td>\n",
       "      <td>[2012.54884,  0.0,  0.0,  0.0,  3153.12649]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>58.4</td>\n",
       "      <td>1033.135066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index         Label  self_auth  self_deg  self_betcent  \\\n",
       "0   consistently_2  consistently   0.000209      10.0      0.000000   \n",
       "2         poorly_5        poorly   0.001552      10.0    194.873669   \n",
       "5         point_19         point   0.002054     242.0      0.000000   \n",
       "7         sense_28         sense   0.000308     116.0      0.000000   \n",
       "24        entire_7        entire   0.002084      84.0      0.000000   \n",
       "\n",
       "                                            pred_auth  \\\n",
       "0    [0.000391,  0.000651,  0.000391,  -1,  0.000269]   \n",
       "2   [0.015114,  0.00691,  0.005939,  0.0034,  0.00...   \n",
       "5                      [-1,  -1,  0.002054,  -1,  -1]   \n",
       "7   [0.013005,  0.101255,  0.000135,  0.001431,  0...   \n",
       "24  [0.001431,  0.000349,  0.002084,  0.000104,  0...   \n",
       "\n",
       "                        pred_deg  \\\n",
       "0      [33,  125,  7,  -1,  136]   \n",
       "2   [176,  198,  173,  135,  10]   \n",
       "5      [-1,  -1,  242,  -1,  -1]   \n",
       "7     [398,  229,  13,  59,  43]   \n",
       "24      [59,  66,  84,  22,  61]   \n",
       "\n",
       "                                         pred_betcent  from_textid  \\\n",
       "0                [0.0,  0.0,  0.0,  -1,  155965.9877]            0   \n",
       "2   [1816.335264,  0.0,  39966.12492,  0.0,  194.8...            0   \n",
       "5                           [-1,  -1,  0.0,  -1,  -1]            0   \n",
       "7   [0.0,  0.0,  10972.03876,  2012.54884,  287.24...            0   \n",
       "24        [2012.54884,  0.0,  0.0,  0.0,  3153.12649]            4   \n",
       "\n",
       "    avg_pred_auth  avg_pred_deg  avg_pred_betcent  \n",
       "0       -0.199660          60.0      31192.997540  \n",
       "2        0.006583         138.4       8395.466771  \n",
       "5       -0.799589          47.6         -0.800000  \n",
       "7        0.023204         148.4       2654.367037  \n",
       "24       0.001094          58.4       1033.135066  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### columns to fit the model - select your X-features here\n",
    "input_col = ['avg_pred_auth','avg_pred_deg','avg_pred_betcent']#'self_auth','self_deg','self_betcent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Selects records in which emotions label is not null, and selects the features \n",
    "that are chosen in 'input_col' above.\n",
    "\n",
    "Splits the train/test data in a 80/20 ratio.\n",
    "\"\"\"\n",
    "## train and val data split\n",
    "#training data input \n",
    "data_X = input_text.loc[~bert_y.isna(),input_col]\n",
    "data_Y = bert_y[~bert_y.isna()]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7237439958457744\n",
      "f1 score: 0.3842592592592592\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs the Random Forest Classifier model\n",
    "and displays the feature importance,\n",
    "accuracy and f1 score.\n",
    "\"\"\"\n",
    "\n",
    "### fit training data on Random Forest Classifier \n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "### display feature importances\n",
    "plt.bar([X_train.columns[x] for x in range(len(rfc.feature_importances_))], rfc.feature_importances_)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "## calculate accuracy and f1 score\n",
    "print('Accuracy:', np.sum(y_pred == y_test) / len(y_test))\n",
    "print(\"f1 score:\", metrics.f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7059587173828379\n",
      "f1 score: 0.41952844695028185\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs the Decision Tree Classifier\n",
    "and displays the feature importance,\n",
    "accuracy and f1 score.\n",
    "\"\"\"\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "### display feature importances\n",
    "plt.bar([X_train.columns[x] for x in range(len(dt.feature_importances_))], dt.feature_importances_)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "## calcualte accuracy and f1 score\n",
    "print('Accuracy', np.sum(y_pred_dt == y_test) / len(y_test))\n",
    "print(\"f1 score:\",metrics.f1_score(y_test,y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: avg_pred_auth, Score: 0.00006\n",
      "Feature: avg_pred_deg, Score: -0.00511\n",
      "Feature: avg_pred_betcent, Score: -0.00001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7167337401012592\n",
      "f1 score: 0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs the Logistic Regression technique\n",
    "and displays the feature importance,\n",
    "accuracy and f1 score.\n",
    "\"\"\"\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train, y_train)\n",
    "\n",
    "# summarize feature importance\n",
    "importance = lg.coef_[0]\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %s, Score: %.5f' % (X_train.columns[i],v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()\n",
    "\n",
    "## evaluation on test set\n",
    "y_pred_lg=lg.predict(X_test)\n",
    "print('Accuracy:', np.sum(y_pred_lg == y_test) / len(y_test))\n",
    "print('f1 score:',metrics.f1_score(y_test,y_pred_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model and predict on the unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict the unlabelled data using the selected model\n",
    "\n",
    "\"\"\"\n",
    "options for model_select : \n",
    "rfc => random forest classifier\n",
    "dt => decision tree\n",
    "lg => logistic regression\n",
    "\"\"\"\n",
    "##### change accordingly\n",
    "model_select = dt\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = input_text.loc[:,input_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### make prediction on unlabelled rows of input_text\n",
    "y_pred = model_select.predict(new_X)\n",
    "\n",
    "### save the selected model for future use\n",
    "\n",
    "filename = 'emo-prediction_rft_model'\n",
    "pickle.dump(model_select, open(model_save_folder +filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make new dataframe to output \n",
    "res = new_X.copy()\n",
    "res['word'] = bert_output['index']\n",
    "res['emo?'] = y_pred\n",
    "res['textid']=bert_output['from_textid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### make new dataframe to output \n",
    "# res = new_X.copy()\n",
    "# res['word'] = bert_output.loc[bert_y.isna(),'index']\n",
    "# res['emo?'] = y_pred\n",
    "# res['textid']=bert_output.loc[bert_y.isna(),'from_textid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(emo_pred_file_name+\".csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load saved model and assign emotion boolean results depending on whether the word is an emotion\n",
    "model_file_path = \"emo-prediction_rft_model\"\n",
    "loaded_model = pickle.load(open(model_save_folder + model_file_path, 'rb'))\n",
    "\n",
    "result = loaded_model.predict(input_text[input_col])\n",
    "res = input_text[input_col].copy()\n",
    "res['word'] = input_text['index']\n",
    "res['emo?'] = result\n",
    "res['textid']=input_text['from_textid']\n",
    "res.to_csv(\"predicted_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with text corpus for prediction result reviews\n",
    "\n",
    "**corpus_path** to read your original corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read orignal text and merge with the prediction \n",
    "### change here\n",
    "corpus_path = \"../source_data/gme_corpus_inputs_10.csv\"\n",
    "###\n",
    "corpus_orig = pd.read_csv(corpus_path)\n",
    "corpus_orig = corpus_orig.reset_index()\n",
    "corpus_orig.rename(columns={'index':'textid'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_pred_auth</th>\n",
       "      <th>avg_pred_deg</th>\n",
       "      <th>avg_pred_betcent</th>\n",
       "      <th>word</th>\n",
       "      <th>emo?</th>\n",
       "      <th>textid</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.199660</td>\n",
       "      <td>60.0</td>\n",
       "      <td>31192.997540</td>\n",
       "      <td>consistently_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006583</td>\n",
       "      <td>138.4</td>\n",
       "      <td>8395.466771</td>\n",
       "      <td>poorly_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.799589</td>\n",
       "      <td>47.6</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>point_19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023204</td>\n",
       "      <td>148.4</td>\n",
       "      <td>2654.367037</td>\n",
       "      <td>sense_28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001094</td>\n",
       "      <td>58.4</td>\n",
       "      <td>1033.135066</td>\n",
       "      <td>entire_7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>I wonder what would happen if the entire WSB a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_pred_auth  avg_pred_deg  avg_pred_betcent            word  emo?  \\\n",
       "0      -0.199660          60.0      31192.997540  consistently_2   0.0   \n",
       "1       0.006583         138.4       8395.466771        poorly_5   1.0   \n",
       "2      -0.799589          47.6         -0.800000        point_19   0.0   \n",
       "3       0.023204         148.4       2654.367037        sense_28   0.0   \n",
       "4       0.001094          58.4       1033.135066        entire_7   0.0   \n",
       "\n",
       "   textid                                            snippet  \n",
       "0       0  Saxobank is consistently rated very poorly fro...  \n",
       "1       0  Saxobank is consistently rated very poorly fro...  \n",
       "2       0  Saxobank is consistently rated very poorly fro...  \n",
       "3       0  Saxobank is consistently rated very poorly fro...  \n",
       "4       4  I wonder what would happen if the entire WSB a...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## visualize some of the examples with the original snippet\n",
    "res.merge(corpus_orig,on='textid',how='left')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### only output predicted emo words together with the original text \n",
    "# emo_agg =  res.loc[res['emo?']==1].groupby('textid')['word'].agg(list).reset_index()\n",
    "# emo_agg['word'] = emo_agg['word'].apply(lambda x: list(set(x)))\n",
    "# emo_agg_with_text = pd.DataFrame(emo_agg)\n",
    "# emo_agg_with_text.merge(corpus_orig,on='textid').to_csv(emo_pred_file_name+\"_agg_with_corpus.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = emo_agg_with_text.merge(corpus_orig, on='textid')\n",
    "# output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.to_csv(emo_pred_file_name+\"_agg_with_corpusV2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res2 = res[res['emo?']==1.0].groupby('textid')['word'].agg(list).reset_index()\n",
    "# res2['word'] = res2['word'].apply(lambda x: list(set(x)))\n",
    "# res2.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only output predicted emo words together with the original text \n",
    "emo_agg =  res.loc[res['emo?']==1].groupby('textid')['word'].agg(list)\n",
    "emo_agg_with_text = pd.DataFrame(emo_agg)\n",
    "emo_agg_with_text.merge(corpus_orig,on='textid').to_csv(emo_pred_file_name+\"_agg_with_corpus.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res2.groupby('textid')['word'].agg(list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
