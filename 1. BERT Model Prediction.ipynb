{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script inputs the corpus and\n",
    "runs several BERT functions to create\n",
    "several network measures\n",
    "\n",
    "For more information on BERT - go to https://huggingface.co/transformers/model_doc/bert.html\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, pipeline\n",
    "import torch\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time \n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#Loads the english pipeline from spacy, with english stopwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "import bert_functions as b_funcs\n",
    "\n",
    "# configure the BERT network \n",
    "\"\"\"\n",
    "Two models are available, one is uncased, the other one is cased, \n",
    "Change according to the importance of CASE in the sentence\n",
    "- bert-base-cased: Model is case-sensitive and there is a difference between 'english' and 'English'\n",
    "- bert-base-uncased: Model is case-insensitive and there is no difference between 'english' and 'English'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "# bert_model = BertForMaskedLM.from_pretrained('bert-base-cased').eval()\n",
    "\n",
    "\"\"\"\n",
    "Input network which is exported from Gephi with network information\n",
    "\"\"\"\n",
    "\n",
    "# network = pd.read_csv(\"MLDA Synonym.csv\")\n",
    "Gephi_output_file_path = \"../source_data/gephi_output_cleaned.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads exported file from Gephi, converts it into a dataframe\n",
    "and sets the Label as the index\n",
    "\"\"\"\n",
    "network = pd.read_csv(Gephi_output_file_path)\n",
    "network.set_index(network['Label'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads in the entire corpus - input file \n",
    "should contain one document per row.\n",
    "\n",
    "Creates an index column for each document.\n",
    "\"\"\"\n",
    "### corpus input path to read the original text\n",
    "corpus_input_csv_path = '../source_data/gme_corpus_inputs_10.csv'\n",
    "\n",
    "df = pd.read_csv(corpus_input_csv_path).rename(columns = {\"snippet\":\"Text\"}) ### load the corpus text \n",
    "df = df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 48782 done\n"
     ]
    }
   ],
   "source": [
    "def output_predict_metrics_from_masked_words():\n",
    "    \"\"\"\n",
    "    For every document in the corpus, runs\n",
    "    BERT functions to detect\n",
    "    masked words and generate network\n",
    "    metrics for predicted words.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame,\n",
    "        Consists of network measures such as degree centrality, betweenness centrality, modularity class and authority scores.\n",
    "    \"\"\"\n",
    "    res_new = pd.DataFrame()\n",
    "    for i in range(0, len(df)):\n",
    "        if i%100==0:\n",
    "            print(f'{i} / {len(df)} done')\n",
    "        input_text = df['Text'].loc[i]\n",
    "        #Creates a dataframe with network measures\n",
    "        res = b_funcs.key_word_predict_with_network_from_sent(input_text,top_k=5)\n",
    "        if res is not None:\n",
    "            res['from_textid'] = df['index'].loc[i]\n",
    "            res_new = res_new.append(res)\n",
    "    res_new2 = res_new.reset_index()\n",
    "    res_new2.to_csv('res.csv', index=False)\n",
    "    return res_new2\n",
    "          \n",
    "result_df = output_predict_metrics_from_masked_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prediction</th>\n",
       "      <th>cleaned_index</th>\n",
       "      <th>Label</th>\n",
       "      <th>self_auth</th>\n",
       "      <th>self_class</th>\n",
       "      <th>self_deg</th>\n",
       "      <th>self_betcent</th>\n",
       "      <th>pred_betcent</th>\n",
       "      <th>pred_auth</th>\n",
       "      <th>pred_deg</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>string</th>\n",
       "      <th>from_textid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>consistently_2</td>\n",
       "      <td>[also, being, actually, currently, still]</td>\n",
       "      <td>consistently</td>\n",
       "      <td>consistently</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0.0, 0.0, 0.0, -1, 155965.9877]</td>\n",
       "      <td>[0.000391, 0.000651, 0.000391, -1, 0.000269]</td>\n",
       "      <td>[33, 125, 7, -1, 136]</td>\n",
       "      <td>[9, 3, 21, -1, 16]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rated_3</td>\n",
       "      <td>[performing, doing, functioning, working, mana...</td>\n",
       "      <td>rated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-1, 174890.4158, -1, 481.203593, 47866.10398]</td>\n",
       "      <td>[-1, 0.001086, -1, 0.001485, 0.000102]</td>\n",
       "      <td>[-1, 169, -1, 19, 9]</td>\n",
       "      <td>[-1, 25, -1, 8, 9]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poorly_5</td>\n",
       "      <td>[highly, high, low, well, poorly]</td>\n",
       "      <td>poorly</td>\n",
       "      <td>poorly</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>194.873669</td>\n",
       "      <td>[1816.335264, 0.0, 39966.12492, 0.0, 194.873669]</td>\n",
       "      <td>[0.015114, 0.00691, 0.005939, 0.0034, 0.001552]</td>\n",
       "      <td>[176, 198, 173, 135, 10]</td>\n",
       "      <td>[25, 23, 11, 5, 11]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seen_10</td>\n",
       "      <td>[written, done, read, said]</td>\n",
       "      <td>seen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-1, 0.0, 35.951423, -1]</td>\n",
       "      <td>[-1, 0.002634, 1.1e-05, -1]</td>\n",
       "      <td>[-1, 18, 8, -1]</td>\n",
       "      <td>[-1, 17, 0, -1]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contradicting_17</td>\n",
       "      <td>[but, and]</td>\n",
       "      <td>contradicting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6263.708295, 10269.73499]</td>\n",
       "      <td>[8.6e-05, 0.000116]</td>\n",
       "      <td>[26, 10]</td>\n",
       "      <td>[18, 8]</td>\n",
       "      <td>Saxobank is consistently rated very poorly fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              index                                         prediction  \\\n",
       "0    consistently_2          [also, being, actually, currently, still]   \n",
       "1           rated_3  [performing, doing, functioning, working, mana...   \n",
       "2          poorly_5                  [highly, high, low, well, poorly]   \n",
       "3           seen_10                        [written, done, read, said]   \n",
       "4  contradicting_17                                         [but, and]   \n",
       "\n",
       "   cleaned_index         Label  self_auth  self_class  self_deg  self_betcent  \\\n",
       "0   consistently  consistently   0.000209        25.0      10.0      0.000000   \n",
       "1          rated           NaN        NaN         NaN       NaN           NaN   \n",
       "2         poorly        poorly   0.001552        11.0      10.0    194.873669   \n",
       "3           seen           NaN        NaN         NaN       NaN           NaN   \n",
       "4  contradicting           NaN        NaN         NaN       NaN           NaN   \n",
       "\n",
       "                                       pred_betcent  \\\n",
       "0                  [0.0, 0.0, 0.0, -1, 155965.9877]   \n",
       "1    [-1, 174890.4158, -1, 481.203593, 47866.10398]   \n",
       "2  [1816.335264, 0.0, 39966.12492, 0.0, 194.873669]   \n",
       "3                          [-1, 0.0, 35.951423, -1]   \n",
       "4                        [6263.708295, 10269.73499]   \n",
       "\n",
       "                                         pred_auth                  pred_deg  \\\n",
       "0     [0.000391, 0.000651, 0.000391, -1, 0.000269]     [33, 125, 7, -1, 136]   \n",
       "1           [-1, 0.001086, -1, 0.001485, 0.000102]      [-1, 169, -1, 19, 9]   \n",
       "2  [0.015114, 0.00691, 0.005939, 0.0034, 0.001552]  [176, 198, 173, 135, 10]   \n",
       "3                      [-1, 0.002634, 1.1e-05, -1]           [-1, 18, 8, -1]   \n",
       "4                              [8.6e-05, 0.000116]                  [26, 10]   \n",
       "\n",
       "            pred_class                                             string  \\\n",
       "0   [9, 3, 21, -1, 16]  Saxobank is consistently rated very poorly fro...   \n",
       "1   [-1, 25, -1, 8, 9]  Saxobank is consistently rated very poorly fro...   \n",
       "2  [25, 23, 11, 5, 11]  Saxobank is consistently rated very poorly fro...   \n",
       "3      [-1, 17, 0, -1]  Saxobank is consistently rated very poorly fro...   \n",
       "4              [18, 8]  Saxobank is consistently rated very poorly fro...   \n",
       "\n",
       "   from_textid  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
